# @package _global_

# to execute this experiment run:
# python train.py -m hparams_search=optuna_{{ model_name}} experiment=hyper/exp1/{{ model_name + "_" + datamodule_name }}.yaml

defaults:
  - override /datamodule: {{ datamodule_name }}.yaml
  - override /model: {{ model_name }}.yaml
  - override /callbacks: default.yaml
  - override /logger: null
  - override /trainer: experiment.yaml

name: "{{ model_name }}"
dataset: "{{ datamodule_name }}"


{%- if model_name == "mlp" or model_name == "autoencoderregressor" or model_name == "deterministicpredictor" or model_name == "probabilisticpredictor" %}
datamodule:
  use_unlabeled_dataloader: False
{%- endif %}

model:
  {%- if model_name == "mlp" %}
  in_features: {{ features }}
  {%- elif model_name == "autoencoder" %}
  enc_in_features: {{ features }}
  enc_out_features: {{ latent }}
  dec_in_features: {{ latent }}
  dec_out_features: {{ features }}
  {%- elif model_name == "autoencoderregressor" %}
  reg_in_features: {{ latent }}
  {%- elif model_name == "vae"%}
  enc_in_features: {{ features }}
  enc_out_features: {{ latent }}
  dec_in_features: {{ latent }}
  dec_out_features: {{ features }}
  {%- elif model_name == "deterministicpredictor" %}
  reg_in_features: {{ latent }}
  {%- elif model_name == "probabilisticpredictor" %}
  reg_in_features: {{ latent }}
  {%- elif model_name == "m2vae" %}
  enc_in_features: {{ add_1(features) }}
  enc_out_features: {{ latent }}
  dec_in_features: {{ add_1(latent) }}
  dec_out_features: {{ features }}
  reg_in_features: {{ features }}
  {%- elif model_name == "srgan" %}
  gen_out_features: {{ features }}
  dis_in_features: {{ features }}
  {%- elif model_name == "semigan" %}
  dis_x_in_features: {{ features }}
  dis_xy_in_features: {{ add_1(features) }}
  gen_x_out_features: {{ features }}
  inv_in_features: {{ features }}
  infer_in_features: {{ features }}
  {%- elif model_name == "ssdkl" %}
  enc_in_features: {{ features }}
  enc_out_features: {{ latent }}
  {%- endif %}

seed: 42

logger:
  wandb:
    name: ${name}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    job_type: "hyperparameter_search"
    group: "{{ model_name + "_" + datamodule_name }}"
    tags: 
      - ${name}
      - "{{ datamodule_name }}"
      - "hyperparameter_search"
    notes: ""

hydra:
  sweep:
    dir: logs/experiments/multiruns/{{ experiment_name }}/${name}/${dataset}__${now:%Y-%m-%d}_${now:%H-%M-%S}
    subdir: ${hydra.job.num}